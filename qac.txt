{
    "question": "Linguistic expressions are often ambiguous, that is they can be interpreted in different ways. Context and world knowledge are often required to figure out the correct interpretation. In some cases, the incorrect interpretation is unexpected and therefore funny -- this is occasionally the case in news headlines.This discussion thread is an attempt to collect examples for ambiguous expressions in various languages.In Lexical ambiguity, a word may have multiple meanings, resulting in multiple interpretations for a phrase or sentence. For example, the interpretation of the headline \"Bar trying to help alcoholic lawyers\" depends on the meaning of the word \"bar\", which can refer to a professional organization of lawyers or to an establishment that serves alcohol.In Structural ambiguity, the different interpretations are due to different syntactic interpretations. For example, the phrase \"a six foot man eating snake\" could refer to a man-eating snake that is six foot long, or a six-foot tall man, who is eating snake [meat], or even a particularly picky snake who only eats six-foot tall men. The sentence \"I cut the cake with a knife\", could either mean that I used a knife to cut the cake, or that i cut some cake that had a knife on/in it.In some cases, structural ambiguity is caused by one or more word forms that can be read as different parts of speech. Consider the sentence \"fruit flies like a banana\". If we read the word \"flies\" as a noun, the word \"like\" should be a verb (a banana is liked by fruit flies) If you read the word \"flies\" as a verb, the word \"like\" should be a preposition (fruit flies, and the way in which it flies is like a banana).There are also examples in which both lexical and structural ambiguity interact. Consider the headline \"Court to try shooting defendant\". In one interpretation \"try\" is read in the sense of \"put on trial\", so the court is putting a shooting defendant on trial. In the other interpretation, \"try\" is read as \"attempt\", in which case the court is attempting to shoot the defendant.You are invited to come up with one or more examples for ambiguous linguistic expressions. Your example can be in English, but ideally you would find an example in another language you speak. Some languages may have additional sources of ambiguity beyond those discussed above. For instance, in Chinese, word segmentation can be a source of ambiguity. Please make sure to explain your example in sufficient detail, so that people who do not speak the language can understand the ambiguity. ",
    "answers": [],
    "comments": [
        "Lexical ambiguity: The child saw the bank -- 1. the child saw the water bank; 2. the child saw the   bank, which is an institution offering certain financial servicesStructural ambiguity: I shot an elephant in my pajamas -- 1. I was wearing my pajamas when I shot an elephant; 2. there was an elephant in my pajamas that I shot.",
        "I was browsing the NYT and found this headline:\"NBC\u2019s New Chief Overhauls Top Ranks\"I suppose the ambiguity is in where you draw the noun phrases. You can either draw them:[NBC's [New [Chief Overhauls]]] Top [Ranks]which would mean that the new chief overhauls by NBC were topping the ranks, with \"Top\" as the verb.Or you can draw them like:[NBC\u2019s [New Chief]] Overhauls [Top Ranks]which would mean that the new chief at NBC was overhauling the top ranks, where \"overhauls\" is the verb.I think this is structural ambiguity? I'm not sure if it's structural -- because of how we draw the noun phrases affects the structure/meaning of the phrases -- or if it's lexical, because both \"overhauls\" and \"top\" could be either a verb or a noun.",
        "An additional form of ambiguity that I think is relevant when considering some of the applications of NLP is spoken or phonetic ambiguity, where there are two (or more) words that sound the same but have different meanings.  While this problem is avoided for textual inputs, it is incredibly important for smart assistants such as Siri which must be able to infer the correct word that is used based upon the context.  An example of a phrase that could be easily misinterpreted by a voice recognition system is the idiom \"go by the book\"; rather than interpreting this phrase to mean following rules, a system could translate \"by\" as \"buy\" and treat it as a command to purchase a book, leading to a clear negative consequence for the user.",
        "My favorite example of lexical and structural ambiguity: \"A panda eats shoots and leaves\"The panda could have consumed leaves and bamboo shootsThe panda could have consumed bamboo shoots and departedThe panda could have eaten, expressed dissatisfaction with its dining experience, and departed",
        "It is typical for Hispanic countries in America to have very different meanings for the exact words. I have a personal story that really portrays how confusing this can be. Colombia has the word \"arrecho/a\" which in their lexicon means \"angry\" or \"furious\". However, I am from Bolivia and the word means something akin to \"lustful\". One day a Colombian friend of mine approached me and told me in Spanish she was very \"arrecha\" with one of my friends as he was being rude and inconsiderate. I just remember being very perplexed by her statement and couldn't really contextualize her comment in a way that made sense. Luckily I asked her to explain and had a good laugh after that. This taught me to tread carefully when speaking Spanish with other nationalities as you can be easily misunderstood. Another example with food is the word \"torta\" which in my country is used solely for identifying cake, whereas, in other countries may also be used to identify a type of sandwich. ",
        "From the Economist: Why Britain must end its use of short sentences. Of course they later modified the title to Why Britain must end its use of short prison sentences. Clear case of lexical ambiguity, and using the adjective \"short\" to modify \"sentences\" (as in a set of words) also makes perfect sense.Another form of lexical ambiguity is cultural/contextual. For instance, the answer to \"Is it okay to wear a pair of pants outside\" depends on what variant of English you speak. In the US \"pants\" means trouser while in the UK it usually refers to underpants. Another example: \"The driver side window is broken.\" can be either left or right window depending on where you are in the world.",
        "A very common example of lexical ambiguity can be found in German. For example, the structure Nominalised Verb followed by a noun. For example the sentence: Das Lesen des Buches (the reading of the book) can mean the act of reading a book, or can describe a book reading. ",
        "Structural ambiguity often emerges due to an XP being a modifier of different elements. For example, in the sentence \"Mary hit the man with her bag,\"The PP with her bag can either modify the verb head hit, or the N head man. In the former scenario, it suggests that Mary used her bag as a weapon to hit the man; The latter interpretation implies that Mary hit a man who had possession of her bag.Parsing languages that do not indicate word boundaries with spaces can be challenging for word segmentation. In spoken language, speakers can utilize context, pauses, and prosody to mentally \"segment\" words, but in written form, these cues are absent. Take the Cantonese phrase \"zung6jau3\" as an example; when unsegmented, it translates to the ADV \"moreover.\" However, when segmented into \"zung6 jau3,\" it conveys the VP \"still have,\" with \"zung6\" meaning \"still\" and \"jau3\" meaning \"have.\"",
        "In Chinese, both Lexical ambiguity and structural ambiguity can be easily found.1) Lexical ambiguity: \u6211  \u8981      \u7092\u9752\u83dc\u3002                                      I    want stir-fried vegetables.                                            will   cook vegetables.2) Structural ambiguity: \u54ac      \u6b7b\u4e86  \u730e\u4eba        \u7684  \u72d7\u3002                                           bite   kill     hunter   's    dog.                                     \u3010\u54ac\u6b7b\u4e86\u730e\u4eba\u3011\u7684\u72d7\uff1aThe dog that bit and killed the hunter.\u54ac\u6b7b\u4e86\u3010\u730e\u4eba\u7684\u72d7\u3011\uff1aThe hunter's dog that was bitten and killed.",
        "In Hebrew, the following sentence is an example of lexical ambiguity: \u05d4\u05de\u05d1\u05e6\u05e2 \u05d4\u05d9\u05d4 \u05de\u05d5\u05e6\u05dc\u05d71. \u05d4\u05de\u05d1\u05e6\u05e2 could mean \"The military operation\", and \u05d4\u05d9\u05d4 \u05de\u05d5\u05e6\u05dc\u05d7 would mean \"was successful\"2. \u05d4\u05de\u05d1\u05e6\u05e2 could also mean \"The sale\" (as in shopping sale), and thus \u05d4\u05d9\u05d4 \u05de\u05d5\u05e6\u05dc\u05d7 would again mean \"was successful\"Interestingly, both words are written with the same vowels (\u05de\u05b4\u05d1\u05b0\u05e6\u05b8\u05e2), so even with the addition of vowels there's still lexical ambiguity and the need to seek overall context.",
        "Lexical ambiguity in Korean arises when a single word has multiple meanings, while structural ambiguity stems from diverse interpretations of a sentence or phrases due to its syntax. Here are some examples for both ambiguity: 1) Lexical ambiguity - \"\ubc30\ub97c \ud0c0\uace0 \uac00\uc790\" , read as \"bae reul tago gaja\".This sentence can mean in few ways: a) Let's go by ship.b) Let's go by pear. c) Let's go by stomach.\"\ubc30\" can mean as a ship, pear, or a stomach depending on its context. It is a noun, on a), representing the object, a ship. \"\ud0c0\uace0\"(tago) is a VP, and \"\uac00\uc790\"(gaja) is a verb that indicates go. In Korean, without VP, such as \ud0c0\uace0,  a verb such as \"\uac00\uc790\"(gaja), would not make much sense. 2) structural ambiguity - \"\ube75\uc744 \uba39\ub294 \uc18c\ub140\" , read as \" bbang eul mukneun sonyu\". The sentence \"\ube75\uc744 \uba39\ub294 \uc18c\ub140\" (bbang eul mukneun sonyu) can be interpreted in two ways depending on the syntactic role of the relative clause \"\uba39\ub294\" (mukneun). a)  \"\ube75\uc744\" (bbangeul) is a noun phrase (NP) representing \"a bread\" followed by the verb phrase (VP) \"\uba39\ub294\" (mukneun) meaning \"eating,\" and the noun (NN) \"\uc18c\ub140\" (sonyu) meaning \"girl.\" Thus, it translates to \"A girl who is eating a bread.\" b) \"\ube75\uc744\" (bbangeul) is again a noun phrase (NP) for \"a bread,\" but now it is modified by the relative clause \"\uba39\ub294\" (mukneun) to indicate \"a bread (\ube75\uc744)\" that a girl (\uc18c\ub140) is eating (\uba39\ub294).\" ",
        "A lexical ambiguity example that always comes up in Kannada (a South Indian Language) is the following example. \u0c85\u0cb5\u0ca8\u0cc1 \u0cae\u0cc7\u0cb2\u0c95\u0ccd\u0c95\u0cc6 \u0cb9\u0ccb\u0ca6\u0ca8\u0cc1Avanu Melakke HodannuThis sentence can be interpreted in two ways:He went upHe passed away (went up to god or heaven would be why people started using it)This is a very common slang throughout Karnataka (where Kannada is spoken) but is mainly used in Bengaluru. This phrase is used frequently in movies and comedy scenes for jokes.",
        "Here is an example of lexical ambiguity in Hebrew: \u05d4\u05de\u05d3\u05e8\u05d9\u05db\u05d4 \u05d4\u05e8\u05e6\u05ea\u05d4 \u05e2\u05dc \u05d4\u05e8 \u05d4\u05db\u05e8\u05de\u05dc -- The word \u05e2\u05dc can mean either on or about thus we have 2 interpretations for the sentence:1. The instructor lectured on Mount Carmel (the instructor was physically on Mount Carmel) 2. The instructor lectured about Mount Carmel (the lecture was about Mount Carmel)",
        "In French, the word 'boite' can be used to describe:- a company, a firm- a box, a container- a nightclubFor instance, the following sentence is an example of lexical ambiguity:Je suis rentr\u00e9 dans une nouvelle boite.1. I got hired at a new company.2. I stepped into a new box.3. I walked into a new nightclub.",
        "1\uff09Here is an example of lexical ambiguity in Chinese:\u6211\u4eec\u80fd\u7a7f\u591a\u5c11\u7a7f\u591a\u5c11If we say this in summer, this sentence means we wear as little as we can.If we say this in winter, this sentence means we wear as much as we can.The term \"\u591a\u5c11\" can have different meanings, either indicating a small or large quantity depending on the specific context in which it is used or referred to.2\uff09Here is an example of structural ambiguity or word segmentation in Chinese: \u559c\u6b22\u770b\u4e66\u7684\u4ebaIf we treat \"\u559c\u6b22\" as a verb and segment the sentence like this: \u559c\u6b22|\u770b\u4e66\u7684\u4eba, this sentence means I like people who like reading books.If we treat \"\u559c\u6b22\" as a part of an adjective and segment the sentence like this: \u559c\u6b22\u770b\u4e66\u7684|\u4eba, this sentence means a person likes reading books.",
        "Lexical Ambiguity:Die Bank steht am Fluss.-&gt; The bank (money) is on the side of the river-&gt; The bench is on the side of the river.Structural Ambiguity Though German has stricter rules for word order preventing ambiguity, Ich sah den Mann mit dem Fernglas.Can be translated literally as:I saw the man with the binoculars. -&gt; This presents the same problem in English, as it can be I seeing the man with the tool binoculars, or I seeing the man who has binoculars",
        "In French, the word remercier can mean to thank, or to fire (lexical ambiguity).For example:\"Le directeur g\u00e9n\u00e9ral a \u00e9t\u00e9 remerci\u00e9.\"Can be translated as:- The general manager was fired.Or as:- The managing director was thanked.",
        "In Chinese, an example of lexical ambiguity is the word \"\u884c\" can mean 'can' or 'doable' (verb), or it can also refer to a 'bank' (noun). Therefore, a phrase like \"\u8fd9\u4e2a\u884c\" could be interpreted as \"This is doable\" or \"This bank\", depending on the context.As for structural ambiguity here's an example: \"\u6211\u770b\u4e66\u7684\u4eba\u8d70\u4e86\". This sentence can be structurally ambiguous depending on how you parse it. It can either mean \"The person who I watch is leaving\" (\u6211\u770b\u7684\u4eba\uff08\u4e66\u4eba\uff09\u8d70\u4e86), or it can mean \"The person who is reading a book is leaving\" (\u6211\u770b\u4e66\u7684\u4eba\u8d70\u4e86). In the first interpretation, \"\u4e66\u7684\u4eba\" might be someone who sells or makes books, while in the second interpretation, \"\u770b\u4e66\u7684\u4eba\" is a person who is currently engaged in the activity of reading a book.",
        "A rather famous example of a structural ambiguity in Latin comes in one of Horace's odes, with the poetic lines: \"...palmaque nobilis, / terrarum dominis euehit ad deos\" which could be translated as something like \"...and the noble palm, exhalts the gods, lords of the lands\" but could also be translated as \"...and the palm, exhalts the noble gods, lords of the lands.\"This rather exciting bit of amibiguity seems pretty structural in nature to me, mostly because it comes as a result of the ambiguous inflections of the nouns here. Nobilis could either be nominative here, denoting that it modifies some kind of singular subject (the palm), or it could ber accusative denoting that it modifies some sort of plural object (the gods). This sort of ambiguity is compounded by the fact that Latin loves to play loosey-goosey with word order, especially with poetry. And so what we end up with is actually a very poetic construction, that quite beautifully makes use of this exact ambiguity to both laud the palm tree and the gods with a single word. So more likely, both the palm and the gods are noble. This makes a lot of sense when we consider that Maecenas, the subject of the poem, is being praised for his bucolic inclinations. What we also end up with, though, is a great crowd of poets who end up always calling palm trees noble...P.S. There's even some lexical ambiguity in here, since palma also means the palm of a hand! It makes sense, since those fronds really come together to look like fingers held up to the sky. It also makes sense, if Maecenas were to raise his hand up as to praise the gods in the sky... It seems like most people agree it's a tree though!",
        "Lexical Ambiguity: In Japanese, the word \"hana\" can have multiple meanings depending on the context. It can mean \"flower\" or \"nose.\" Consider the following sentence: \u82b1\u304c\u54b2\u3044\u3066\u3044\u308b\u3002 (Hana ga saite iru.) This sentence can be interpreted in two ways: a) Flowers are blooming. b) The nose is blooming. Without any further context, it is difficult to determine the intended meaning of \"hana.\" Structural Ambiguity: Japanese sentences often omit subjects and rely heavily on context. This can lead to structural ambiguity. Consider the following sentence: \u884c\u3063\u305f\u3089\u3001\u6559\u3048\u3066\u304f\u3060\u3055\u3044\u3002 (Ittara, oshiete kudasai.) This sentence can have two different interpretations: a) If you go, please tell me. (Assuming the subject is the person being spoken to) b) If I (need to )go, please tell me. (Assuming the subject is the speaker) The ambiguity arises because the subject is not explicitly stated, and it can only be inferred from the context. These examples showcase some of the common sources of ambiguity in Japanese language. Context and world knowledge are crucial for disambiguating these expressions and understanding their intended meanings.",
        "An example of lexical ambiguity in Italian would be the phrase:\"Volo con le penne\". This can be translated as either \"I fly with pens\" or as \"I fly with feathers\", as penne can mean pens/quills/feathers.For an example of structural ambiguity (this is a pretty famous one):\"Ho cucinato le pappardelle al cinghiale\". This can be translated as either \"I cooked pappardelle for the boar\" or \"I cooked pappardelle with boar\".",
        "Lexical Ambiguity:In Hindi, the word \u0932\u093e\u0932 (laal) be either a term of endearment added to the end of a name or the color red. \u092e\u0941\u0915\u0947\u0936 \u0932\u093e\u0932 \u091c\u0942\u0924\u093e \u092a\u0939\u0928 \u0930\u0939\u093e \u0939\u0948\u0964 (Mukesh laal jootha pahan raha hain)This sentence can be translated in two ways, dependent on how the reader translates \"laal.\" 1) \"Mukesh laal is wearing shoes.\" 2) \"Mukesh is wearing red shoes.\" Structural Ambiguity:Structural ambiguity in Hindi can be common when postpositions are present. A postposition relates a noun to some other word in the sentence. \u0920\u094b\u092e \u0928\u0947 \u0915\u0941\u0926\u0924\u0947 \u0939\u0941\u090f \u092c\u093e\u0928\u0930 \u0915\u094b \u0926\u0947\u0916\u093e\u0964 (Tom ne koodhte huain banar ko dekha)1) Tom saw a jumping monkey. 2) As Tom was jumping, he saw a monkey.In this case the postposition is \u0928\u0947 (ne), and is either linking Tom to the action of jumping or the action of seeing. This link is essential to the sentence translation. ",
        "Lexical Ambiguity:In Hebrew, the word \u05de\u05e1\u05d2\u05e8\u05ea can mean picture frame or organized activity. \u05d4\u05d9\u05dc\u05d3\u05d9\u05dd \u05e0\u05de\u05e6\u05d0\u05d9\u05dd \u05d1\u05de\u05e1\u05d2\u05e8\u05ea can have two definitions: The kids are in an organized activity The kids are in a picture frameDepending on the context surrounding the sentence Structural Ambiguity:\u05d4\u05d9\u05d0 \u05e8\u05d0\u05ea\u05d4 \u05d0\u05ea \u05d4\u05db\u05dc\u05d1 \u05e2\u05dd \u05d4\u05ea\u05e4\u05d5\u05d7 in Hebrew translates to: She saw a dog with an appleTherefore, did a woman see a dog and happen to have (eating / holding) an apple? Or, did a woman see a dog that had an apple? (presumably carrying in its mouth\" ",
        "Lexical Ambiguity:The word \"bank\" can have multiple meanings.\"There was a accident at the bank\" could imply eitherThere was an accident at the financial bankThere was an accident at the river bank Structural Ambiguity:The use of the word \"with\" can impact the meaning of a sentence.\"We saw them with a telescope\" could imply eitherWe saw them using a telescopeWe saw a group of people that was in the presence of a telescope ",
        "Lexical Ambiguity:The word \u7b97\u8d26 (suan zhang) in Chinese typically means \"calculating the bill\" and is used in the context where one may \"settle the bill\" with the waiter after a meal. However, it's also used to mean \"argue\", in the sense that you are going to \"argue to settle a disagreement\". This can lead to a sentence like:\u7b49\u4ed6\u56de\u6765\uff0c\u6211\u8981\u627e\u4ed6\u7b97\u8d26\uff01Which can either mean:Once he comes back, I will find him to pay the bill. orOnce he comes back, I will find him and fight/argue with him. ",
        "An example of Lexical Ambiguity in Spanish would be the word \"LLAVE\". Llave has two meanings, it could mean a key, or a faucet, depending on the context.\"Us\u00e9 la llave de la casa\" can be translated to:I used the key to the house.orI used the faucet from the house.An example of Structural Ambiguity can be:\"Mi madre vio perro con el pelo mojado\"This is translated to \"My mother saw dog with wet hair\"This can be interpreted in two different ways:1.) My [mother who has wet hair] while she saw the dog2.) My mother saw the [dog that has wet hair]",
        "Lexical Ambiguity: A friend started an security related startup. security in this case could mean either:  - A financial security. In this case, the startup could be related to help people managing their portfolio consisting different assets such as equity, bonds, etc.  - Keeping people safe. In this case, the startup could be related to help customer with safety related issues, such as home monitoring system.",
        "Lexical Ambiguity example in English:\"The actor played a gambler in the movie.\"The word played is ambiguous and could mean:The actor performed as a gambler character in the movieThe actor took advantage of a gambler, where \"played\" means to be taken advantage of",
        "In Chinese, there are many lexical ambiguities as well.Lexical Ambiguity: \u4ed6\u4e22\u4e86\u996d\u7897 is a phrase that could have multiple meanings. The first and more common use means \"He lost his job\". Yet the word \u201c\u996d\u7897\u201d could mean literal \"bowls\" where the second meaning will be \"He lost his bowl\".Segmentation Ambiguity in Chinese: In terms of word segmentation ambiguities the professor mentioned. A good example can be:\u8fd9\u4e9b\u4fb5\u7565\u8005\u628a\u4ed6\u4eec\u7684\u5730\u74dc\u5206\u6389\u4e86 This sentence can have two ways to segment it. 1) \u8fd9\u4e9b\u4fb5\u7565\u8005\u628a\u4ed6\u4eec\u7684\u5730|\u74dc\u5206\u6389\u4e86 which means \"These invaders divided their land\". and 2) \u8fd9\u4e9b\u4fb5\u7565\u8005\u628a\u4ed6\u4eec\u7684\u5730\u74dc|\u5206\u6389\u4e86 \"These invaders divided their sweet potatoes\". The ambiguous part is on how one would segment the object noun in the sentence. Interestingly, the more common interpretation should be the first way yet Google translate returns the second interpretation which is quite funny.",
        "In Russian, nouns take various suffixes (or cases) to convey their grammatical meaning and function in a sentence. While these cases do a fine job of reducing ambiguity (better than the English language, in my opinion), they do not altogether prevent lexical and structural ambiguity. Below is an example of each.Lexical AmbiguityThe word \u041c\u0438\u0440 means \"world\" or \"peace\" and \u041e\u0431\u0440\u0435\u0441\u0442\u0438 mean \"to gain or find\".For this reason the phrase \"\u041e\u0431\u0440\u0435\u0441\u0442\u0438 \u043c\u0438\u0440\" has lexical ambiguity since it can mean \"to find peace\" or \"to gain the world\" (two obviously antithetical sentiments).Structural AmbiguityThe sentence \"\u041e\u043d \u043f\u043e\u0441\u043b\u0430\u043b \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u0434\u0435\u0432\u0443\u0448\u043a\u0435 \u0431\u0435\u0437 \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u0430\" translates to \"He sent a message to the girl without a computer.\" However, it could also mean \"He sent (without a computer) a message to the girl\".In the first translation, \"she\" is affected by the preposition \"without a computer\". In other wordsThe second translation assumes \"he\" is affected by the preposition \"without a computer\" while the first assumes \"she\" is.Due to the structural ambiguity in this sentence, one is left to use context clues in order to resolve the proper meaning.",
        "Lexical Ambiguity: \u201c\u4ee5\u5099\u4e0d\u6642\u4e4b\u9700\u201dThis Chinese phrase has a similar meaning to \u201cjust in case of need\u201d / \u201cfor a rainy day\u201d. \u201c\u4e0d\u6642\u201d here means \u201cany unexpected moment\u201d.However, \u201c\u4e0d\u6642\u201d can also means \u201cfrequent\u201d / \u201coften\u201d. Then, the phrase becomes \u201cfor a frequent need\u201d.Segmentation Ambiguity: \u201c\u975c\u591c\u601d\u201dIt comes from a famous poem. The meanings of the characters are \u201cquiet / silent\u201d, \u201cnight\u201d and \u201cthought / thinking\u201d respectively.Different ways of grouping the characters can cause difference in meanings:(\u975c\u591c)\u601d: means \u201cthinking in a silent night\u201d / \u201cthoughts about a silent night\u201d\u975c(\u591c\u601d): means \u201cquietly thinking at night\u201d",
        "Lexical Ambiguity: I was surprised to see a big crane in front of my house.This is an example of lexical ambiguity in English, where the sentence could be interpreted in two different ways because the word crane can hold two different meanings in English.1. I was surprised to see a big crane (a big bird) in front of my house2. I was surprised to see a big machine (used for moving large objects between places) in front of my house.Structural ambiguity: I looked at my sister wearing my sunglasses on the beach.This can be interpreted in multiple ways: 1. I was wearing my sunglasses on the beach when I looked at my sister.2. I looked at my sister who was wearing my sunglasses on the beach.",
        "Ambiguity in Spanish: Lexical and Structural AmbiguityExample: \"Puedes pescar un pez con un gato.\"This sentence is an example of both lexical and structural ambiguity in Spanish. In English, the sentence translates to \"You can catch a fish with a cat\". However, \"pescar\" in Spanish can mean both 'to fish' (catch fish) and 'to catch' (grab or take hold of something).Also, \"gato\" can mean both 'cat' and 'jack' (as in a car jack).In one interpretation, we're using a feline pet to somehow catch a fish, which is absurd and funny. But in the other interpretation, we're using a car jack to grab or hold a fish, which is equally strange and humorous.This is a simple yet effective demonstration of how a sentence can have multiple interpretations due to the dual meanings of the words involved and their arrangement in the sentence.This ambiguity can only be resolved through context or additional information. For instance, if this sentence is found in a surreal children's storybook, the first interpretation might be plausible. Conversely, if it's in a context where conventional tools are being creatively repurposed, the second interpretation might be the correct one.",
        "Spanish:Lexical ambiguity: \"El profesor dej\u00f3 la tarea\"The sentence can be interpreted as \"the teacher left the homework\"  (in a location, i.e., at home) or as \"the teacher assigned homework\"Structural ambiguity: \"Comi el arroz con un tenedor roto\"The sentence could be interpreted as \" I ate the rice with a fork that was broken\" or \"The rice that I ate had a broken fork within\"",
        "Lexical Ambiguity: Farmer Bill Dies in HouseDid a farmer named Bill die in a house? Or did a legislative proposal relating to farmers die in the House of Representatives?",
        "All the \"natural\" languages I would have an answer for have been posted.I wanted to see if we could extend this concept for programming languages? (or is it not ambiguous because eventually the c++ compiler figures out what to do?)Lexical Ambiguity(function overloading in c++):  void f(int x)\n void f(float x)\n void f(double x)This is valid code. One of these will get called, but which depends on the arguments that get passed in, so your behavior will be different for f(1), f(1.0)Structural Ambiguity(multiple inheritance in c++)class A{\n  void f(){}\n }\n\n class B{\n  void f(){}\n }\n\n class c: A, B\n {\n }\n\n C obj;\n obj.f();In the above example, c inherits from A &amp; B. Both have a method f defined. This will throw an exception since the compiler is unsure of what it should do.(only if you call obj.f() however)",
        "After the class, I thought of the ambiguity that I have noticed in the Chinese language, shockingly it was more frequently encountered than I thought. Here are the example I got for structural ambiguity:\u6211\u7684\u623f\u95f4\u6ca1\u6709\u9501The ambiguity here comes from the word \"\u9501\" which could be interpreted as the noun \"lock\" or the state \"locked\". In the former interpretation, the sentence means -- My room does not have a lockBut in the latter, it means -- My room is not lockedAdditionally, the discussion of word segmentation in Chinese reminded me of a classic joke I used to read: A teacher introduced himself to a parent and said:\u6211\u662f\u6570\u5b66\u738b\u5b50\u79e6\u8001\u5e08And the parent replied:\u4f60\u597d\u79e6\u8001\u5e08This is a funny joke in Chinese because the teacher meansI am Wang ziqin who teaches mathematicsBut the parent misunderstood it because \u738b\u5b50 can also be interpreted as \"prince\", so he answered: Hello Mr.Qin, which means that he took the sentence as \"I am teacher Qin, the prince of math\"It is a rather complicated example, since the ambiguity was introduced because of both lexical ambiguity (\u201c\u738b\u5b50\u201d) and word segmentation (\u6211\u662f/\u6570\u5b66/\u738b\u5b50\u79e6/\u8001\u5e08 vs. \u6211\u662f/\u6570\u5b66\u738b\u5b50/\u79e6/\u8001\u5e08). As I was explaining I realized it is actually pretty hard to explain the ambiguity here, and I feel like it'll be awkward if I try to explain why it's funny... but trust me it is :)",
        "Since I'm interested in Chinese religion-Taoism, I'd like to say a very famous Taoist saying for ambiguity:\u201c\u9053\u53ef\u9053\u975e\u5e38\u9053\u201dit can mean.\u9053\u53ef\u9053\uff0c \u975e\u5e38\u9053\uff1aThe \"Tao\" that can change is not the real \"Tao\" (the Tao here is the Tao from the natural point of view, the laws of nature,) and the other way around is that everything in the world has its own laws, and the real laws are eternal, not chaotic (like the laws of physics, the changing of the seasons, etc.). Seasons, etc.)\u9053\u53ef\uff0c\u9053\u975e\uff0c\u5e38\u9053\uff1aIt is common for some people to say that something is right and others to say that it is not.\u9053\uff0c\u53ef\u9053\u975e\uff0c\u5e38\u9053\uff1a It is all too common that one thing can be misrepresented and said to be wrong!",
        "In French the phrase ne...personne can have multiple meanings includingnobody anybodyThis can lead to lexical ambiguity. For example, the following sentence could have different interpretations:Personne n'aime personne ici 1) Nobody likes anybody here2) Nobody likes nobody hereThere is also the possibility of structural ambiguity in French due to confusion regarding which noun in a sentence an adjective modifies. For example, the phrase: un professeur d'ing\u00e9nierie allemand could be interpreted as:1) A professor of German engineering2) A German professor of engineering",
        "In Arabic:\"\u0637\u0631\u0642\u062a \u0627\u0644\u0628\u0627\u0628 \u062d\u062a\u0649 \u0643\u0644\u0651 \u0645\u062a\u0646\u064a\" - \"Taraqtul bab hatta kalla mitni\"This sentence when written means: \"I knocked on the door until my arm/hand got numb\" but when spoken it means \"I knocked on the door until she spoke to me\" This is taken from a poetic phrase that has a second line: \"\u0641\u0644\u0645\u0627 \u0643\u0644\u0651 \u0645\u062a\u0646\u064a \u0643\u0644\u0645\u062a\u0646\u064a\" - \"Fa lamma kalla mitni, kallamatni\"Which explains the ambiguity somewhat because it means: \"when/after my arm/hand got numb, she spoke to me.\" This is from a phrase my mother used to say to explain the richness of the Arabic language, it goes on to also speak about the encounter between the person who knocked on the door and the lady who answered in a similar manner to this, but it might be difficult to explain that in English. Arabic has diacritical marks (or accentuation) on letters, when used in the sentence it differentiates the phonetics of each word and changes the meaning of the word. This can be seen In the second sentence between \"kalla mitni\" and \"kallamatni\". mitni here means arm or hand, or the part of the body which was used to knock on the door, in which case \"kalla\" means that this object has, itself, gotten numb or tired. The second word \"kallama\" is a past tense of the verb \"to speak\" with the added suffix \"t\" to indicate that the speaker is female and the \"ni\" is another suffix which refers to the object of speaking, which is similar to the word \"me\" in English. I am curious as to how NLP deals with Arabic language in this case and how it can be used with Arabic, especially in the case of diacritical marks and accents, which change each word dramatically if used incorrectly.",
        "Lexical ambiguity in Hindi:Rupa is a common Indian name for women and also the name of a popular brand of undergarments. This brand released a series of commercials in the late-80s where famous actors would proclaim \"\u0930\u0942\u092a\u093e \u0915\u0940 underwear!\" (Rupa ki underwear!), which can be interpreted as both \"underwear by Rupa (the brand)\" and \"underwear belonging to Rupa (the person)\". \u0915\u0940 (ki) in this context means \"created by\" and also \"belonging to\". So the joke goes - if I'm wearing Rupa's underwear, what's Rupa wearing?",
        "One example of lexical ambiguity: The engagement before the wedding was quite short.This is ambiguous because \"engagement\" can refer to committing to a marriage in the future, which might seem relevant to the sentence as it precedes \"before the wedding\". However, \"engagement\" can also just be an arrangement of a time/place that could've also happened \"before the wedding\", such as a party.One example of Structural ambiguity:  I studied Computer Science at Columbia University.This is ambiguous, because it can mean that I studied the major \"Computer Science\" at the college named \"Columbia University\", or it can mean I studied the organization \"Computer Science at Columbia University\" to learn more about its course offerings.",
        "Lexical Ambiguity Example:I saw her duck.Interpretation A: the subject saw her bird duckInterpretation B: duck(verb). The subject saw her do the action of duckingStructural ambiguityI spotted the child with binocularsDid you spot a child who had binoculars? Or did you use binoculars to spot the child?",
        "Lexical Ambiguity example:Let's take a look at this meme. The name of the picture in Chinese is \"Python \u5165\u95e8\". Here we have two ambuiguities:1. Python can be either the programming language Python or one Genus to categorize animal (what  we always called \"snake\").2. \"\u5165\u95e8\" in Chinese have two meanings. One is more straightfoward, like showing in the picture, a snake is preparing to enter the door; another meaning refers to the action or status that you just start to learn some skills.  Therefore, \u201cPython \u5165\u95e8\u201d can also be interpreted as start to learn Python , or many books will use this name which means this book is \"Python for beginners\".",
        "Lexical Ambiguity: \u201cthe cat is sitting on the mouse\u201d\"mouse\" could be an animal or a computer accessoryStructural Ambiguity: \u201ctall children run in the family\u201dtall children in the family enjoy runningchildren in the family tend to be tall",
        "Lexical Ambiguity: \"We fly over a million people\"\"over\" could mean greater than or aboveStructural Ambiguity: \"An average girl's hostel\"Is the hostel average or is the hostel for the average girl",
        "Lexical Ambiguity: \"I saw a bat in the park\"Could be referring to the flying mammal or a baseball batStructural Ambiguity: \"Visiting relatives can be boring\"Could be interpreted as the act of visiting relatives can be boring or the relatives themselves can be boring to visit",
        "Lexical Ambiguity: \"The old man the boat\" The word \"man\" is a verb here and not \"the old man\"Structural Ambiguity: \"The boat sailed on the river sank\"The word \"sailed\" serves as an adjective in this case, not as a verb. In this sentence, it means the boat that sailed on the river and it sank",
        "Lexical Ambiguity: \u9019\u9053\u83dc\u5f88\u96e3\u5403 It can be expressed as \"This dish tastes bad\" or \"This dish is difficult to eat\"Structural ambiguity: \u6211\u559c\u6b61\u4e0a\u4e00\u5bb6\u5e97 It can be expressed as \"I like the previous store.\" or \"I like the certain store.\"",
        "Lexical ambiguity: \u201cI forgot where the match was.\u201dThe word \u201cmatch\u201d could refer to a thin piece of wood used to light a fire or a competition between people.Structural ambiguity: \u201cI saw my friend running to the mall.\u201dI was running to the mall and saw my friend along the way.I saw my friend while he was running to the mall.",
        "Lexical ambiguity: \"He broke the record.\"\"record\" could refer to a music disk or an achievementStructural ambiguity: \"The chicken is ready to eat.\"The chicken could be ready to be consumed by others or ready to consume something itself",
        "Lexical Ambiguity: \"Pope's Effort to Eradicate Monkeys From Vatican Strongly Opposed by Capuchins\"\"Capuchins\" can refer to a Catholic religious order or to a small, omnivorous species of monkey.Structural Ambiguity: \"On my walk home, I turned into a barbershop\"\"Turned into\" can be a verb and prepositional phrase, as in entering a barbershop, or a compound verb, as in transforming into a barbershop.",
        "Lexical: Fans love the fast break.In basketball, the fast break refers to when a team pushes the pace of play down the court. However, to someone unfamiliar with basketball, fast break could also be interpreted to a quick (temporal) timeout breakStructural: The scouts judge LeBron on the court.This could mean the scouts are evaluating Lebron physically playing on the court. Alternatively, the scout could be the one on the court, judging Lebron. ",
        "Another example of lexical ambiguity in Chinese is \"\u7092\u9c7f\u9c7c\u201c. The straight up translation is stir-fry squid as a dish, but this can also mean got fired. ",
        "Greek:My Greek is very rusty but here are some examples I was able to think of, all lexical:\u03b3\u03b5\u03b9\u03ac \u03c3\u03bf\u03c5 - this could mean hello, good-bye, afternoon, etc. It really depends on the context\u03b5\u03af\u03bd\u03b1\u03b9 \u03b4\u03c5\u03bd\u03b1\u03c4\u03cc\u03c2 - could be \u201che is strong\u201d or \u201cit is possible\u201d\u03c0\u03ac\u03c9 \u03ad\u03be\u03c9 - \u201cI\u2019m going out\u201d - either going outside or going \u201cout\u201d as in out on the town\u03b8\u03b1 \u03c0\u03ac\u03c9 \u03b3\u03b9\u03b1 \u03bc\u03c0\u03ac\u03bd\u03b9\u03bf - \u201cI'll go for a swim\u201d or \"I'll go for a bath/to the bathroom\u201dEnglish:Lexical:Perhaps acronyms could count as a form of lexical ambiguity, at least in the context of NLP models:ADC has allowed for great improvements in quality of life for people in the past few decades. In this sentence, this could either refer to AC/DC electrical converters (often abbreviated as ADC), or Automatic Drip Coffee machines (many more meanings here for this acronym: https://acronyms.thefreedictionary.com/ADC)A more standard exampleThe chicken is cooked well.The chicken could either be cooked well, as in good, or it could be cooked well done, as in overcooked.Structural:The ducks were quacking at the pond with the people.The ducks were quacking at the pond, and people were present there - or the both the ducks and people were quacking together at the pond.Garden Path Sentence:Fat people like to cook with comes from animals and plants.",
        "Lexical ambiguity: The team's power play was a complete disaster.In hockey, a \"power play\" refers to a team's numerical advantage from having more players on the ice. Outside of the hockey context, a \"power play\" can be a team's strategy with respect to a political maneuver, for instance.Structural ambiguity: The team celebrated the victory with a group hug.The team engaged in a group hug together, or the team received a group hug from an outside party (i.e. fans).",
        "This is an example of lexical ambiguity: In Chinese, we say \"\u4f60\u5403\u597d\u4e86\u5417?\"  \"\u597d\" can mean good so one interpretation is \"Did you eat well?\"It can also mean a sense of completion so another interpretation is \"Have you finished eating?\"",
        "In urdu the word: \"\u06a9\u0644\" can mean both \"yesterday\" as well as \"tomorrow\".This can lead to lexical ambiguity in a sentence such as:\"\u0645\u06cc\u06ba \u06a9\u0644 \u067e\u06be\u0631 \u0622\u06cc\u0627\"which translates to both:I came again yesterdayI'll come again tomorrowAn example of structural ambiguity is the sentence:\"\u0645\u062c\u06be\u06d2 \u0627\u0633\u06cc \u0628\u0627\u062a \u0633\u06d2 \u0688\u0631 \u062a\u06be\u0627\"This typically means: \"That's what I was afraid of\"but \"\u0628\u0627\u062a\" means \"conversation/topic\" so the sentence can also mean \"I was afraid of this conversation\" if emphasis is put on this word",
        "Lexical ambiguity with the homonym \u201cpen\u201d is present in the sentence \u201cYou left the pen open.\u201d Pen can either refer to 1. A writing instrument or 2. An enclosure for an animalStructural ambiguity is evident in the sentence \u201cJohn decided on the plane.\u201d Either 1. John makes a decision while physically on a plane or 2. John is choosing a specific plane to go with. ",
        "Lexical Ambiguity In Korean, \"\uc5ec\ubcf4\uc138\uc694\" both mean \"hello/hey/you there (over phone usually)\" or \"is this my partner\"This is because there exist lexical ambiguity for the same exact word [\uc5ec\ubcf4](partner)+[\uc138\uc694](are you) and [\uc5ec\ubcf4\uc138\uc694](honorific form of \uc5ec\ubd10\uc694 or hey).Structural AmbiguityKorean grammar doesn't share strict parallel structure of English and structural ambiguity can form with \"and\"[\uc640] placed between NP[\ucfe0\ud0a4]/[\ucf00\uc774\ud06c] (also no DT although this has no bearing on the ambiguity)\ub0b4\uac00 \ub9db\uc788\ub294 \ucfe0\ud0a4\uc640 \ucf00\uc774\ud06c\ub97c \uba39\uc5c8\ub2e4. (I ate delicious cookie and cake)&gt;&gt; \ub0b4\uac00 [\ub9db\uc788\ub294 \ucfe0\ud0a4]\uc640 [\ucf00\uc774\ud06c]\ub97c \uba39\uc5c8\ub2e4. ( I ate [delicious cookie] and [cake])&gt;&gt; \ub0b4\uac00 [\ub9db\uc788\ub294 [[\ucfe0\ud0a4]\uc640 [\ucf00\uc774\ud06c]]]\ub97c \uba39\uc5c8\ub2e4. (I ate [delicious [[cookie] and [cake]]]",
        "Lexical Ambiguity in Chinese\u770b in Chinese could be \"see\", \"visit\", \"take care of\" or \"guard\"\u6211\u53bb\u770b\u4ed6Can mean \"I am going to visit him\"Can mean \"I am going to take care of him\"Structural Ambiguity in Chinese\u5979\u544a\u8bc9\u5979\u5988\u5988\u8fd9\u4ef6\u4e8bCan mean \"She told her mother about this matter.\"Can also mean \"She told her this matter about her own mother .\"",
        "Lexical Ambiguity: After talking with the stranger, he seemed to be very bright.In this case the homonym bright: \"bright\" could refer to being physically bright, perhaps due to the sun and any reflections, or it could refer to being an intelligent individualStructural Ambiguity: The old man found the turtle by the pond.This sentence could be interpreted as the old man found a turtle while he was standing by the pond or perhaps the old man found the turtle standing by the pond.While looking at different lexical and structural ambiguous examples, I also thought about one in the language of Urdu.The word \u0632\u0628\u0627\u0646 translates into both language and tongue in English so the following sentence \u062a\u0645\u06c1\u0627\u0631\u06cc \u0632\u0628\u0627\u0646 \u0628\u06c1\u062a \u062e\u0631\u0627\u0628 \u06c1\u06d2 can translate into either \"Your language is very bad\" or \"Your tongue is very bad\". This could be interpreted as either the person is unable to speak in the Urdu language or it could mean that they have a foul tongue and say bad things.",
        "Lexical Ambiguity: She can no longer bear children. This sentence could either mean the woman cannot handle the emotional stress associated with dealing with children, or could refer to the woman physically being unable to produce offspring.Structural Ambiguity: The officer subdued the dangerous man with a weapon.This sentence could either mean that the officer used a weapon to subdue the dangerous man, or perhaps that the officer successfully subdued the dangerous man who was holding the weapon.",
        "Lexical Ambiguity: \"Bank tellers give customers an account of the latest interest rates.\" Account can refer to a narrative or explanation, as in \"give an account of.\" , i.e. it means that bank tellers are providing customers with information or an explanation about the latest interest rates.Account can also refer to a financial record of money held in a bank, like a savings or checking account. In this interpretation, it means that bank tellers are helping customers create or manage their financial accounts related to the latest interest rates.Structural Ambiguity : We should be discussing violence on TV. The sentence could either mean discussing the \"violence\" topic on a TV show or it could mean discussing a specific type of violence, which is \"violence on TV \"."
    ]
}
{
    "question": "Hi Everyone,We will be using Ed Discussion for class Q&amp;A - NLP Summer 2023. As a headsup, the course start details for Summer 2023 is available on Canvas. Please refer it for more details .Class Time: 07/03 - 08/11 Tuesday &amp; Thursday 4:10pm-7:20pm, EDT/ UTC-4 Important: extra session on Friday July 7 (4:10-7:20pm) to make up for 4th of July.Edstem is the best place to ask questions about the course, whether curricular or administrative. You will get faster answers here from staff and peers than through email.Here are some tips:Search before you postHeart questions and answers you find usefulAnswer questions you feel confident answeringShare interesting course related content with staff and peersFor more information on Ed Discussion, you can refer to the Quick Start Guide.All the best everyone for this semester!Professor and TA Team",
    "answers": [],
    "comments": [
        "Hello-how do I log into Canvas? Thanks!",
        "Will there be zoom recordings if we have to miss a session?",
        "Will the final be in-person?",
        "I see that 10% of the grade is participation. I am a CVN student and I'm wondering how can I participate in this class, other than asking questions in Ed. One way that was mentioned was during Zoom. Will we (CVN students) be able to ask live questions on Zoom during the broadcasted lectures? That would be awesome! ",
        "To get participation score through Ed, do we have to put our UID somewhere so that participation can be properly recorded?"
    ]
}
{
    "question": "Will the final exam solution be provided so that we can check our deduction?Thanks",
    "answers": [
        "Most rubric items will contain an explanation for the correct/expected answers. I won\u2019t be able to provide a complete sample solution.\u00a0"
    ],
    "comments": []
}
{
    "question": "I was wondering whether our participation grade would also be added to Canvas, or if the grade we currently see with the exam taken into account already includes that",
    "answers": [
        "The participation grade is not included on Courseworks currently. I can post these tomorrow (essentially, unless there is no record of you ever participating in the course, you will get 100% of the participation score.)\u00a0Note that you need to weigh the different scores according to the formula on the rubric to compute your final score.\u00a0"
    ],
    "comments": []
}
{
    "question": "When can we expect to get our final exam grades back?",
    "answers": [
        "Grading is currently a little more than halfway complete. We're hoping to finish this week."
    ],
    "comments": []
}
{
    "question": "In the example input/output sequence resulting from the sequence:['&lt;START&gt;', 'a', 'black', 'dog', '.', '&lt;END&gt;'] It seems the period token ('.') is skipped as the last input/output pair shown consists of:input = [START,a, black, dog]output = ENDIs this a typo? Should this input/output pair be:input = [START,a, black, dog]output = .and then an additional input/output pair would be the following?input = [START,a, black, dog, .]output = ENDThanks!",
    "answers": [
        "Yes the missing . is a typo.\u00a0"
    ],
    "comments": []
}
{
    "question": "In HW5 Part 1, it says \"We will need to create encodings for all images and store them in one big matrix\". Does this mean we should be encoding an image with img_encoder.predict() , and then resizing it to 1x299x299x3, since it returns a 2048 size vector? Or does \"create encodings\" mean just resizing the image to be 299x299x3, and then returning that \"encoding\" of the image in required shape? ",
    "answers": [
        "I think the first one (resizing it to 1x299x299x3), as the Model.predict_generator function waas asking for a 4-dimensional array. "
    ],
    "comments": []
}
{
    "question": "Should we decrease/increase the number of epochs so that the model should finish training around 40%?",
    "answers": [
        "The accuracy should be at least 40% for reasonable results. If that takes more epochs, it\u2019s okay to increase the number of epochs.\u00a0"
    ],
    "comments": []
}
{
    "question": "My machine does not process the pdf downloading command on anaconda jupyter, so I printed the html to get pdf instead. And HW5 asks for pdf submission, but coursework only allows compressed files. Shall we submit a link containing the pdf, or will a compressed pdf file be fine?Thank you!",
    "answers": [
        "You should submit a zip file that contains both the notebook and the PDF."
    ],
    "comments": []
}
{
    "question": "regarding the second part of the question, why are all q=1, is it always the case?q(3 | 1, 3,3) = 1q(2 | 2, 3,3) = 1q(1 | 3, 3,3) = 1q(5 | 1, 5, 5) = 1q(4 | 2, 5, 5) = 1q(3 | 3, 5, 5) = 1q(2 | 4, 5, 5) = 1q(1 | 5, 5, 5) = 1",
    "answers": [
        "I think it's because there's no other way to map the alignments one you have some already known"
    ],
    "comments": []
}
{
    "question": "Do people who take exam via Zoom today also have to set this up? \u00a0I can\u2019t find an announcement regarding this.",
    "answers": [
        "No, students taking the exam on Zoom will have real-time proctoring (i.e. I or one of the TAs will be watching you take the exam). "
    ],
    "comments": []
}
{
    "question": "I just want to make sure, I see that there's a (*) next to the Semantic Parsing topic on the exam topic overview. Would all of the concepts under it not be tested in the exam?",
    "answers": [
        "that's correct, none of these topics will be tested on the exam. Note that this only applies to full-sentence semantic parsing, not semantic role labeling. "
    ],
    "comments": []
}
{
    "question": "How are these constraint penalty scores c(w,y_1:t) computed?They need to be differentiable",
    "answers": [
        "Good question. I tried to find this in the He et al paper, but they simply say \"Each constraint function c applies a non-negative penalty given the input w and a length-t prefixy1:t\"https://aclanthology.org/P17-1044/"
    ],
    "comments": []
}
{
    "question": "One way is to one-hot encode over all possible paths upto some reasonable length, say 10. Is there another way such paths are encoded to form a feature in practice?",
    "answers": [
        "You would one-hot encode the possible paths. Note that you would only instantiate the features that are actually seen during training, so you wouldn't have to create a dimension for each possible path -- only for the ones that have been observed. "
    ],
    "comments": []
}
{
    "question": "Hi!I was wondering whether the cheat sheet needs to be handwritten? Or can it be printed?Thanks",
    "answers": [
        "It can be handwritten or typed, but it must be a physical copy."
    ],
    "comments": []
}
{
    "question": "Hi , In this solution there is a Start symbol and so can we assume that there is an end symbol as well?",
    "answers": [
        "Sure. "
    ],
    "comments": []
}
{
    "question": "Hi,For this exercise I was wondering if I am interpreting the solution correctly. So is the reason that we are returning the sum over states (sum_s) rather than the max (max_s) so that we can consider multiple paths rather than the most likely path? In what use case would quantifying the possible tag sequences be relevant?",
    "answers": [
        "Your understanding is correct. I can't really think of a specific use case -- maybe you want to get an estimate of how ambiguous a sentence is. The number of possible POS sequences might be a good proxy for that. "
    ],
    "comments": []
}
{
    "question": "Hello -- has the gradescope dummy exam been posted yet?",
    "answers": [
        "I still get an error when I click on gradescope that I have no account, so I think not? Unless something is wrong on my endI also can't make an account without a course ID",
        "It's available now. Please do NOT try to add the course using a course ID, but instead use the link on Courseworks to access Gradescope. "
    ],
    "comments": []
}
{
    "question": "HI Professor Bauer/TAs, I was wondering when the dummy exam will be posted? When I clicked on Gradescope via coursework, this course was not added yet. THanks! ",
    "answers": [
        "Same situation here; I assume it is not activated yet.",
        "#283 "
    ],
    "comments": []
}
{
    "question": "Hi,If we have grammar:S -&gt; NP VVP -&gt; V NPWanted to confirm: does the order matter? If we have a \"NP V\" can it only be S, or will it be S and VP?Thanks,Vidur",
    "answers": [
        "#81"
    ],
    "comments": []
}
{
    "question": "Why does END symbol gets added to the 6 words but not the START symbol even though they are both given in the corpus of sentences? ",
    "answers": [
        "#14"
    ],
    "comments": []
}
{
    "question": "Would it be possible to just explain in words why this base case works? I am just trying to get the big picture. Also what does the p and r represent? ",
    "answers": [
        "Does this help?, P() is the probability, q and r are words for arbitrary indices in a sentence. Here, assumed q occurs before r."
    ],
    "comments": []
}
{
    "question": "For CVN students taking the exam asynchronously, will we be filling out our answers on Courseworks, or do we need to print out and scan answers?Additionally, do we need to print out the \"cheat sheet\" or can we keep it alongside Proctorio when taking the exam? ",
    "answers": [
        "You need to print out the pdf, or write your answers on a different set of sheets if necessary. Then scan the solution and upload to Courseworks.\u00a0The cheat sheet should be a physical paper, not a pdf.\u00a0"
    ],
    "comments": []
}
{
    "question": "In the solutions, P(eats | dog)= (1+1)/(3+7) = 1/5 is it (1+1) for 'eats' because 'dog' is only followed by 'eats' 1 time? I was under the impression that it was the number of occurrences of the word + 1 for smoothing. For n-grams, are we looking for the number of occurrences of the n-gram phrase? Such as \"Dog eats\" only appears once hence the (1+1)?dog bites humandog bites duckdog eats duckduck bites humanhuman eats duckhuman eats salada) dog eats saladP(dog | START)= (3+1)/(6+7) = 4/13\nP(eats | dog)= (1+1)/(3+7) = 1/5\nP(salad | eats)= (1+1)/(3+7) = 1/5\nP(END | salad)= (1+1)/(1+7) = 1/4\nP(dog eats salad) =\nP(dog | START) P(eats | dog) P(salad | eats) P(END | salad) =\n4/13 x 1/5 x 1/5 x 1/4 = 1/325 = 0.0031",
    "answers": [
        "That\u2019s correct. The context \u201cdog\u201d (which appears three times in total) is followed only once by \u201ceats\u201d. Therefore the raw probability would be 1/3 and with add-one smoothing (1+1)/(3+7).\u00a0"
    ],
    "comments": []
}
{
    "question": "Hi!For the ungraded exercise on the Viterbi &amp; forward algorithms, I was confused by  c): \"...write out the parameters of a trigram model that assigns the same probability distribution to a set of surface sequences...\". Are the parameters in question the probabilities for any one transition (i.e. N-&gt;N, N-&gt;V, etc.). If so, would a trigram model require more nodes (since the transition probability depends on the bigram context, so N-&gt;V would need to be a single node, and so on)?  Hope this makes sense! ",
    "answers": [
        "So the trigram model should be a set of trigram probabilities defined over words, not POS tags.\u00a0Yet, it should assign the same probability to any surface word sequence that the HMM does.\u00a0"
    ],
    "comments": []
}
{
    "question": "^^ since I do not see them on the review sheet... Thanks!",
    "answers": [
        "Pretty sure the professor said they will not be on the exam"
    ],
    "comments": []
}
{
    "question": "Hi,I don't quite understand the calculations for:P(Alex | Alex saw) = 3/4P(Kim | Alex saw) = 1/4P(Alex | Kim saw) = 3/4P(Kim | Kim saw) = 1/4Could you please show how it was calculated? Thanks.",
    "answers": [
        "I believe there are four possible sentences based on the given PCFG:s1: \"START START Alex saw Kim STOP\"s2: \"START START Kim saw Alex STOP\"s3: \"START START Alex saw Alex STOP\"s4: \"START START Kim saw Kim STOP\"After \"Alex saw\" or \"Kim saw\" for each sentence, the word will be either \"Alex\" (probability = 3/4) or \"Kim (probability = 1/4)."
    ],
    "comments": []
}
{
    "question": "Hi all,I had quick question regarding different languages and using it in MT. In unsupervised learning, is there a way, that the MT can detect a brand new language (which it never encountered before) and learn it based on the structure and how repetitive some words may be? And, in that case, is there some NLP problem which we can devise which creates a \"new language\" based on what the model thinks is relevant. Essentially, I am trying to understand the relevancy of a new language vs. new types of sentences/words. Is the syntax of a language something that can be picked up?Thanks,Vidur",
    "answers": [],
    "comments": []
}
{
    "question": "Hi,Was just wondering if the TA led review was posted on Courseworks yet. Thanks!!",
    "answers": [
        "There was no TA led review this semester. Sorry.\u00a0"
    ],
    "comments": []
}
{
    "question": "Hi,I think in a previous lecture, professor had mentioned he may post some questions from old exams which are not going to be used anymore. I was wondering if there was a way to get them, as was not able to find it.Thanks!Vidur",
    "answers": [
        "These have been posted in the assignments section, labeled \u201cbonus\u201d questions.\u00a0"
    ],
    "comments": []
}
{
    "question": "Hello,Maybe I missed this but could anyone please inform which link are CVN students using for the synchronous final exam?Thank you in advance!",
    "answers": [
        "The regular class link, but I will send out a reminder tomorrow.\u00a0"
    ],
    "comments": []
}
{
    "question": "for the IBM model 2 question part 3, why is it q(5 | 1, 5, 5) * t(skwk | fly) not q(1 | 5, 5, 5) * t(skwk | fly)?",
    "answers": [
        "From my understanding, the parameters are: q(j|i,l,m) which correspond to alignment value i takes value j given source sentence length l and foreign m.q(5 | 1, 5, 5) = q(fly|skwk, 5, 5)I think there might be a typo in the last one:q(5 | 1, 5, 5) * t(et | the) should actually be: q(1| 5, 5, 5)* t(et | the)"
    ],
    "comments": []
}
{
    "question": "For the exam, will we need to have memorized some of the internal structures of these large databases mentioned in class? Or just generally know what they are used for and what information they hold?",
    "answers": [
        "You should know the structure, for example the various lexical relations recorded in wordnet, as well as what a synset is etc.\u00a0"
    ],
    "comments": []
}
{
    "question": "Dear Prof. and TAs, still confused about the solutions in Ungraded Exercise Solution: Linear Models and Feature Functions.For part a), it seems that the feature function consider the unique combinations of Current Word and its Candidate POS Tag, Previous word and its POS Tag .According to the training data, Unique words (V): time, flies, like, fruit (Total: 4)Unique POS tags (T): N, V, P (Total: 3). Therefore, The total number of unique combinations for the feature function \u03a6 based on the provided training data is much more than 8 My question is: How we decide which example to give?For part b), is the assigned vectors are arbitary or by calculatio; If calculate, would you mind showing the process?For the weight vector, my understanding is it ensures the dot product between v and the feature vector for each word and its correct tag is maximized, leading to the correct POS assignment for all tokens in the training corpus. My question is: do we just assign arbitrarily a high weight like 1, then the dimension is depending on the number of functions in 1)?For part c), For a log linear model, Then how are we expected to show the parameters, i.e., the vector v? Can you please give a sample~Thank you!",
    "answers": [],
    "comments": []
}
{
    "question": "I personally work on recommendations and ranking use GPT-4 not only to generate high quality relevance labels at scale but also generate feature scores to be fed into a more light-weight transformer at production, generate queries and more. LLMs/GPT models have many new applications in the field of recommendations. This paper is an interesting application of using GPT for query generation given item sequences a user has interacted with.[2304.03879] GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation (arxiv.org) ",
    "answers": [],
    "comments": [
        "Wow! So cool!! Just quick question -- is there a way here, or on what you work with, for spam recommendations to get filtered out? I.e. I am assuming that new responses are used to \"re-train\" further recommendations like in pre-training. I guess there may be malicious people who want to wrongly influence the models, such as maybe a company recommending its products and \"inserting itself\" into the model through user input. Is there a way we have devised to prevent that or at least detect that in some way? "
    ]
}
{
    "question": "In part 3 of the last ungraded exercise, why is the last q(a_i | i) term q(5|1,5,5) and not q(1|5,5,5)?  For reference the solution has:q(5 | 1, 5, 5) * t(skwk | fly) *q(4 | 2, 5, 5) * t(e| a) *q(3 | 3, 5, 5) * t(qta | ate) *q(2 | 4, 5, 5) * t(skwk | bird) *q(5 | 1, 5, 5) * t(et | the) = 2/3",
    "answers": [
        "Because the question asks specifically about example 3, which is \"the bird ate a fly\". So, for q(5 | 1,5,5), 5 indicates et(the). "
    ],
    "comments": []
}
{
    "question": "Could you please provide some hints on how to answer part b?Thank you",
    "answers": [
        "I think to prove b you would just need get the dependency tree in a different way from a, which you would do by using at least 1+ different transition to arrive at the same result. I think you would focus on trying get to some variation using arc-right vs arc-left as a strategy, which can be done by changing how you use shift."
    ],
    "comments": []
}
{
    "question": "I just wasn't quite certain what this term meant as I'm going through the lecture notes. Is it referrig to a case where a sentence seems to be ambiguous but it is not? Or am I off base here",
    "answers": [
        "Which lecture is this from? Thank you!",
        "Correct me if I'm wrong, but I think it's when a parsing algorithm has multiple paths to get to the same state.",
        "I agree with Chris. I think it can happen when we are confused about meaning of sentence and this is probably a good queue to use some sort of semantic analysis and contextual clues."
    ],
    "comments": []
}
{
    "question": "I was curious about this and asked Bing Chat: One of the challenges of training RNNs is that the output vocabulary can be very large, especially for natural language tasks. This means that the softmax layer, which computes the probability distribution over the output vocabulary, can be very expensive to compute. The softmax layer requires computing the dot product between the hidden state and each output word vector, and then applying the exponential function and normalization. This can be slow and memory-intensive, especially for long sequences.There are several methods that have been proposed to make the training of RNNs with softmax more efficient. Some of these methods are:Sampled softmax: This method reduces the computation by sampling a subset of the output vocabulary and computing the softmax only over this subset. The subset usually includes the true output word and some negative samples drawn from a predefined distribution. This way, the softmax layer only needs to compute a small number of dot products and exponentials, instead of the entire vocabulary. Sampled softmax can greatly reduce memory consumption and still maintain accuracy 1 2.Hierarchical softmax: This method organizes the output vocabulary into a tree structure, where each node represents a group of words or a single word. The softmax layer then computes the probability of each node along the path from the root to the true output word, instead of computing the probability of each word in the vocabulary. This way, the softmax layer only needs to compute a logarithmic number of dot products and exponentials, instead of a linear number. Hierarchical softmax can speed up training and also handle large vocabularies34.Adaptive softmax: This method partitions the output vocabulary into several clusters based on their frequency, such that more frequent words are in smaller clusters and less frequent words are in larger clusters. The softmax layer then computes the probability of each cluster and each word within the cluster separately, using different parameters for each cluster. This way, the softmax layer can adapt to the distribution of the output vocabulary and reduce computation for more frequent words5.",
    "answers": [],
    "comments": []
}
{
    "question": "For the part b) of transition-based parsing ungraded exercise, does this require that we show another sequence for the same sentence, or use another sentence? Thank you!",
    "answers": [
        "I believe part b) is asking us to show another sequence for the same sentence. Please see #263."
    ],
    "comments": []
}
{
    "question": "(1) Is l, length of the source sentence? and m, of the target sentence? We condition on l,m when estimating \"how often does position i align with position j\" . I see why if one sentence is much longer than the other the indices that are aligned are different. But in general, for sentences of close-enough length which seems a reasonable assumption fot translations, is there still a need to condition on the sentence lengths being exactly the same?  (2)The denominator in this expression: Isn't this simply \"count of occurrences of position i such that source language sentence length is l and target language sentence length is m\"Which (for any i &lt;=m) would simply be the number of sentences in the corpus such that source language sentence length is l and target language sentence length is m?",
    "answers": [
        "1) m is the length of the source sentence (the F sentence) and l is the length of the target sentence (the E sentence). Even if two sentence pairs are close in length, they would be handled differently. This is obviously a very limiting assumption in IBM Model 2. 2) Yes, correct. The denominator is simply the number of all sentences with length less than m. "
    ],
    "comments": []
}
{
    "question": "In practice, is Negative Sampling with Binary Classification loss (with Sigmoid) commonly used instead of softmax for training LSTMs efficiently ?",
    "answers": [
        "As far as I'm aware, negative sampling is not commonly used when training RNNs. "
    ],
    "comments": []
}
{
    "question": "Hi,Are we allowed to bring some blank sheets or will they be provided at the exam for rough work/calculations/drawing Viterbi calculation graph /transition graphs etc. It would be very helpful during the exam.Thank you",
    "answers": [
        "You will be provided blank sheets , however bring your calculators incase you need to do some calculations !"
    ],
    "comments": []
}
{
    "question": "Hi Professor Bauer,I was wondering if you are going to post more ungraded exercises (e.g. AMR) on the later half of the semester? Thanks! ",
    "answers": [
        "Sorry for that, I'm going to upload some more material tomorrow, but don't expect a ton of it. "
    ],
    "comments": []
}
{
    "question": "For the forward algorithm, this is one of the equations in the solution:\u03c0[2,V] = \u03c0[1,N] \u00b7 P(V|N) \u00b7 P(flies |V) + \u03c0[1,V] \u00b7 P(N|V) \u00b7 P(flies|N)) = (1/4 \u00b72/4 \u00b7 2/6) + (1/12 \u00b7 0 \u00b7 2/6)) = 1/24 = 0.04166I am confused as to where the numbers for the second part of this equation (\u03c0[1,V] \u00b7 P(N|V) \u00b7 P(flies|N)) are coming from. I thought the equation would be \u03c0[2,V] = \u03c0[1,N] \u00b7 P(V|N) \u00b7 P(flies |V) + \u03c0[1,V] \u00b7 P(V|V) \u00b7 P(flies|V)), but perhaps I am understanding the forward algorithm wrong?Thanks in advance",
    "answers": [
        "I don't think you can go from V to V and that's why P(V|V) is not possible. I think the forward algorithm is the same as Viterbi but instead of taking the max we sum all the probabilities. "
    ],
    "comments": []
}
{
    "question": "Regarding the n-gram an data sparsity issues, do we have to master at applying the smoothing and back-off approaches (like discounting, Katz' Backoff) to refine the probability for the final exam?Thank you~",
    "answers": [
        "Yes, you should understand the various methods in sufficient detail to be able to apply them to a (artificially small) data set. "
    ],
    "comments": []
}
{
    "question": "Hi,Q1) What do the red arrows signify in this solution?Q2) Can we draw the diagram as above for exam instead of drawing the alternative table representation?Can you also provide the solution for part c please.Thank you",
    "answers": [
        "For Q1, I believe that the red arrows indicate possible transitions from one state back to a previous state."
    ],
    "comments": []
}
{
    "question": "In the past, I have gotten emails with instructions for taking the exam with Proctorio with notes from the instructor (timing, cheatsheet, etc..). Will this be sent out?",
    "answers": [
        "Yes. This will be sent out early next week.\u00a0"
    ],
    "comments": []
}
{
    "question": "In the Exam topics post on courseworks, there is an incomplete topic heading \"Struc\" and I was wondering what this overarching topic might be? Thanks so much!",
    "answers": [
        "That's a typo. You can safely ignore it."
    ],
    "comments": []
}
{
    "question": "Hi,I was going over the solution for the feature functions exercise, I am not sure I understand how to solve the problem. Could you please help me with the same since I am really confused?1) How is the order in which you select the word wi decided? Since there are 3 sentences and the solution doesn't necessarily select words in any of the sentence order.2) Why is there no ti-1 for below feature function. 3) Why do we have one wi with time, when time appears thrice in the three sentences with different parts of speech (N and V)Part b) The weight vector has all 1s because we want all the features to be true for correct POS tagging?Part c) Can you please release the solutionThank you.",
    "answers": [
        "I'm also struggling to understand this concept, so any further explanation would be very helpful. Thanks!",
        "1) I don't believe it necessarily matters how the word w_i is being selected, as feature functions can be any type of function that takes into account some or all of the possible arguments (w_{i-1}, wi, t_{i-1}, and t_i in this case) and outputs 0 or 1.2) This feature function is just an example. I believe that w_i = \"fruit\" and t_i = \"N\" is sufficient in this case because all examples of \"fruit\" in the training data are of the form \"fruit/N.\" In the case of \"flies,\" for example, where both \"flies/V\" and \"flies/N\" appear in the training data, the corresponding feature functions include additional information (e.g., w_{i-1}) that describe whether \"flies\" is being used as a noun or verb.3) Like in the case of \"flies/N,\" in which there are two feature functions in the given solution (6, 7), we could have more than one w_i with time feature function if we chose to create one or more additional feature functions.",
        "Seems like basically we need to get all highest amount of params possible that will hold true for all the given sentences. Hence, some have more parameters if they are all holding true and some are very limited (like unigram type)"
    ],
    "comments": []
}
{
    "question": "I believe this was covered in class already but just want to confirm whether or not we need a calculator for the exam? Is it required or just encouraged (to make our lives easier)?",
    "answers": [
        "It's not a hard requirement, but a basic 4-function calculator may make some computations easier."
    ],
    "comments": []
}
{
    "question": "Hi! Would it be possible to know HW4 results a little before the middle of next week, so that we know if we should try to submit HW5? ",
    "answers": [
        "We're hoping to finish before HW5's due date so that everyone can make an informed decision about HW5. We'll do our best to finish grading as fast as possible. :)"
    ],
    "comments": []
}
{
    "question": "Do we need to consider left and right context for part 4 like we do in part 5, or is this something we can do for part 6? ",
    "answers": [
        "Part 4 does not consider the left and right context at all, only the target word itself. So this is something you could incorporate in part 6. "
    ],
    "comments": []
}
{
    "question": "Are we allowed to change the number of best words (from 10) returned from the bert predictor? And if the resulting list doesnt contain any candidate words, should we be returning nothing?",
    "answers": [
        "Yes and yes. \u00a0"
    ],
    "comments": []
}
{
    "question": "Are we allowed to use word_tokenize from the NLTK library?",
    "answers": [
        "Yes."
    ],
    "comments": []
}
{
    "question": "There are some final tweaks I'd like to make to improve my precision and recall, but there are times where I will make an edit, re-write the output to the predict file, and run perl, but then will get the error I have illegal division. Even when I revert the code back to its original form, it will from thereon return an error. Is this happening for others and are there any ways to resolve this? ",
    "answers": [
        "The reason is that the .predict file is formatted \u201cincorrectly\u201d. If you are running Python in windows, it writes out windows style line endings (CRLF). But the perl evaluation script expects Unix style line endings (CR).\u00a0Opening the file in a text editor and saving it again usually fixes the issue.\u00a0"
    ],
    "comments": []
}
{
    "question": "Hi everyone!I'm trying to download the data for HW5, but get the following error.I've tried downloading both through the requests package (I'm on Windows) and by visiting the site directly. Any help would be greatly appreciated!",
    "answers": [
        "Please try again, there was a permission issue that has now been fixed. ",
        "I think I was having the same issue but after using incognito tab, it worked. Might be a caching issue."
    ],
    "comments": []
}
{
    "question": "What is the approximate accuracy we should expect from lesk algorithm? I am getting fairly low number and was unsure why.ThankshamidSeyedhamidreza Alaie",
    "answers": [],
    "comments": []
}
{
    "question": "Hi, I am getting interesting results where my Word2Vec score is higher than Bert. Wondering if this could be possible or anyone has thoughts on what could be the issue:Word2Vec: Bert:Thanks!",
    "answers": [
        "I am having the same issue with mine :/",
        "Could you look at cases where the predictions disagrees and BERT gets it wrong. Then try to see out why ?  Sometimes it is because of incorrect masking index.Check if word2vec candidates appear in the BERT lexicon? If it does, how far is the rank of candidates in the list of most probable substitutes ? "
    ],
    "comments": []
}
{
    "question": "If anyone comes across this error, you can comment in modeling_tf_utils.py in the transformers package in Lib/site-packages/transformers to fix it",
    "answers": [
        "Great, thanks for sharing this with the cohort!"
    ],
    "comments": []
}
{
    "question": "Hi, Part 2 says : Note that you have to sum up the occurence counts for all senses of the word if the word and the target appear together in multiple synsets. So if a lemma appears in 2 different synsets, do I have to count this lemma twice or do I have to consider them as 2 distinct lemma? Also, What can cause a variability in the accuracy in part 2? I ran the same code twice and I got 2 different results: ",
    "answers": [
        "You would have to sum together the .count value for the two lexemes to get a single score for the lemma. The result should always be the same for part 2-- this is a bit odd. "
    ],
    "comments": []
}
{
    "question": "Are there any computation restrictions for this assignment?My solution for Part 6 takes about ~3.5 hours of computational time to complete. I have not been using GPU. Given that I also submit the actual part6.predict file, is this acceptable?",
    "answers": [
        "Yes, as long as you document your approach in a comment in this case, since we won\u2019t actually be able to run it.\u00a0"
    ],
    "comments": []
}
{
    "question": "Hi, I just wanted to make sure that I understand the following terms correctly. Lemma: is the base form of a word. (e.g. run)Word form: is any modified or inflected version of the lemma ( e.g. runner, running, runs, etc.)Lexeme: represents the core meaning and all related word forms of a word. This means it covers the lemma and its inflected forms (e.g. run ( base form) + runner, running, runs (inflected forms)) . Is that true ? ",
    "answers": [
        "Yes, a lexeme is a word with a particular sense. There may be multiple lexemes for the same lemma. \u00a0"
    ],
    "comments": []
}
{
    "question": "Hi, Would like to ask what to do the synonym when the word2vec model doesn' t have its embeddings.There are some synonym use multiple words and '-' to make a new word and those the gensim model could not find embeddings for them.Thanks",
    "answers": [
        "I asked a similar question privately in Ed \u00a0and this is the response the professor provided: \u201c It\u2019s okay to ignore candidates that do not have a word2vec entry.\u00a0One thing you could try is to replace the white space in multi word candidates with an underscore _.\u00a0Another option would be to obtain word vectors for moving and picture and then average them.\u201d\u00a0(The example I provided was a multi word \u201cmoving picture\u201d)"
    ],
    "comments": []
}
{
    "question": "Just wondering having repeated overlapping words in context/def would mean for the overlap count. So for example:Context: bank bankDefinition: bank notWould the overlap here be one or two?Context: bank notDefinition: bank bankHow about here?",
    "answers": [
        "It's my understanding that you can treat the context and definition as a set - only one instance of the word is counted. For all the examples the overlap would be 1."
    ],
    "comments": []
}
{
    "question": "In part 1, do the order of the lemmas need to match the output in the assignment description? ",
    "answers": [
        "I think as long as it has the same contents then it should be fine."
    ],
    "comments": []
}
{
    "question": "Hello Professor Bauer,Would you be able to clarify the weightage of the final exam points, especially for the last two weeks' material? It's complex and some of us may find reviewing it challenging due to time constraints.Thanks for your guidance.",
    "answers": [],
    "comments": []
}
{
    "question": "For anyone having trouble / waiting a long time to upload the GoogleNews file to colab or GCP (like I was):pip install gdowngdown https://drive.google.com/u/1/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&amp;export=downloadsource: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive?page=1&amp;tab=scoredesc#tab-top ",
    "answers": [],
    "comments": []
}
{
    "question": "Hi,I remember professor mentioning that dependency parsing models are considered discriminative models and not generative. Could you please elaborate more on why this is the case? Thankyou.",
    "answers": [
        "In transition based dependency parsing, the model predicts P(transition | state) directly, rather than using Bayesian inference to infer the best state.\u00a0"
    ],
    "comments": []
}
{
    "question": "Hi! For part 5, I keep getting errors like this, even when I try the verbose trick that was mentioned.Should I worry about it / will I get points off if I leave it like this? My part5.predict file looks like this:Thank you",
    "answers": [
        "When you call predict, you can add the parameter verbose=False, which should suppress the output. Alternatively, you can modify the code so that it writes your output directly into a text file, rather than printing to stdout and then piping it into a file. "
    ],
    "comments": []
}
{
    "question": "Hi,I noticed the solution for the ungraded exercise of HMM - Viterbi &amp; Forward algorithm contains only parts a and b. Could you maybe post the answer to part c as well?Thank you!",
    "answers": [],
    "comments": []
}
{
    "question": "From the lecture slides - \"CFGs are context free: applicability of a rule depends only on the nonterminal symbol, not on its context.\u2022 Therefore, the order in which multiple non-terminals in a partially derived string are replaced does not matter. We can represent identical derivations in a derivation tree.\"However for HW3 and according to post #81, not considering the correct order for terminals would result in incorrect results.So does this mean, NP \u2192 D N cannot be written as NP -&gt; N Dbut NP \u2192 NP PP - (1)  does it mean just that it is okay to either substitute NP or PP first . Or does it mean (1) can be written as NP -&gt; PP NP ? (which doesn't seem to be correct)Please let me know if I am understanding this correctly.Thank you in advance!",
    "answers": [
        "When you have a rule NP \u2192 NP PP, it doesn't matter if you substitute NP or PP first in a derivation. The productions you can use to substitute NP depend only on the nonterminal itself, not on the context it appears in. "
    ],
    "comments": []
}
{
    "question": "If so, could you please share the zone that worked? I've tried several zones with no luck",
    "answers": [
        "Please refer to the video recently posted on Courseworks (recorded by TA - Shreya) in Files -&gt; homework5 -&gt; hw5_gcp_tutorial.mp4"
    ],
    "comments": [
        "was able to get an L4 in us-central-a"
    ]
}
{
    "question": "Hello teaching staff, for part 6 I just want to confirm: in the previous post, it said that any interesting or creative solution will get full credit. Does this mean even without being the best predictor(in terms of the highest precision and recall) is fine?And for part 3, I tried two ways to write the code, and seems like the result scores are different. For both ways, the simple lesk algorithm did not outperform the WordNet frequency baseline. I'm wondering if there is a standard answer to predictions in predict file for this part.Thank you!",
    "answers": [
        "That\u2019s right, for part 6 you do not necessity have to get the highest score.\u00a0Not sure I understand your question about part 3. There are some valid modifications in part 3 that would all be in line with the specification leading to different results.\u00a0"
    ],
    "comments": []
}
{
    "question": "Both my Word2Vec and Bert predictors produce the exact same precision and recall results, but I'm not sure if this means that there's something wrong with my Bert predictor since the assignment handout states that it performed slightly better than the Word2Vec predictor in experiments?  I can't seem to find any bugs in the Bert predictor and I'm following the encoding method directly from the handout, but I'm not sure if some kind of optimization needs to be added for the Bert predictor to perform better to achieve full credit?  I've included the results output for both parts below for reference:Total = 298, attempted = 298\nprecision = 0.115, recall = 0.115\nTotal with mode 206 attempted 206\nprecision = 0.170, recall = 0.170\n",
    "answers": [
        "I have the same concern, but for what it's worth, I have the same output that you do for both. ",
        "My Bert predictor did outperform Word2Vec slightly and even if the scores are identical the predicted results should be different. Word2Vec will always give you the same synonym for the same lemma and pos regardless of context whereas Bert will give different answers. For instance, Word2Vec gives \"shining\" as the replacement for \"bright\" in the first two sentences whereas Bert gives \"promising\" and \"shiny\" respectively in my code. "
    ],
    "comments": [
        "I get the exact same performance for both the models as well. According to post #182  I am guessing that should be okay."
    ]
}
{
    "question": "Just wondering what should happen if an input to this function is a word that contains an underscore. So something like hot_dog for instance. What I'm doing right now includes \"hot dog\" as a candidate, but I realize that may not be totally correct. Should we account for this?",
    "answers": [
        "Yes. Replacing underscores with white space is actually the correct way to handle this."
    ],
    "comments": []
}
{
    "question": "\"In this part, you should implement your own refinements to the approaches proposed above, or even a completely different approach. \"Does this mean that we can implement a refinement for any (i.e., at least one) of the four approaches from parts 2-5? Or we must implement a refinement for each of the approaches? Thanks!",
    "answers": [
        "Just one new refinement , not refinement for each !"
    ],
    "comments": []
}
{
    "question": "Can we get some test cases for part 2 wn_frequency_predictor ?",
    "answers": [
        "I don\u2019t think I have any specific test cases. Can you report your performance measures?"
    ],
    "comments": []
}
{
    "question": "I was trying to follow the video tutorial to set up my GPU in google cloud. However, there is \"tensorflow has resource level errors\" when setting up the deep learning VM. Anyone having any idea on how to deal with this?",
    "answers": [
        "Yeah, it means that particular zone doesn't have enough resources. Try it with us-west4-a, worked for me"
    ],
    "comments": []
}
{
    "question": "Hi,After going to OH I'm confused as to how can I possibly compute the similarity without using the gensim model from part 4 (when I tried that it took a very long time to load).Here's what I have so far:def better_predict(self, context : Context) -&gt; str:\n        # Converts information of context into suitable masked input representation for DistilBERT model\n        masked_text = ' '.join(context.left_context + ['[MASK]'] + context.right_context)\n        input_toks = self.tokenizer.encode(masked_text)\n        indices = self.tokenizer.convert_ids_to_tokens(input_toks)\n        masked_index = indices.index('[MASK]')\n        input_mat = np.array(input_toks).reshape((1, -1))\n\n        # Runs the DistilBERT model on the input representation but only takes first 100 words\n        outputs = self.model.predict(input_mat, verbose=0)\n        predictions = outputs[0]\n        best_words = np.argsort(predictions[0][masked_index])[::-1] # Sorts in increasing order\n        best_words = self.tokenizer.convert_ids_to_tokens(best_words[:100])\n        \n        max_sim = -1\n        synonym = None\n        #for word in best_words:\n            # compute similarity between word and context.lemma, check if larger than max and replace\n            # max_sim and synonym accordingly\n        #return synonym\n        # Overall idea: have bert predict 100 best candidates and out of those select the one most similar to the target word\n        return \"\"\nAs mentioned in the comments, the idea is to iterate over best_words, and calculate each word's similarity with context.lemma, then return the maximum synonym found.Any ideas will be appreciated. Thanks in advance!",
    "answers": [],
    "comments": []
}
{
    "question": "Since the Final is being administered on gradescope for Zoom participants, can we get the gradescope course ID to get setup there in preparation? Thanks",
    "answers": [
        "You won\u2019t need the course Id. Instead you will be able to access the exam through the Gradescope link on courseworks. I will post a dummy exam prior to the official exam so you can make sure everything works properly.\u00a0"
    ],
    "comments": []
}
{
    "question": "Hi all,Are the solutions for any of the homeworks after Homework 1 going to be posted?",
    "answers": [
        "Solutions for HW2 and HW3 have been uploaded now. Please check the files section on the Courseworks page."
    ],
    "comments": []
}
{
    "question": "I ran part 5 in CPU, and it turns out results like :Does anyone know how to get rid of the two-bar line? Thank you!",
    "answers": [
        "I was just told to try adding \"verbose=0\" when you call predict, i.e:self.model.predict(input_mat, verbose=0)\nAnd it seems to work!"
    ],
    "comments": []
}
{
    "question": "Do we need to consider the lower or upper case of the synonyms/lemma/word? Thank you!",
    "answers": [
        "Please use lowercase."
    ],
    "comments": []
}
{
    "question": "You would break the tie, so return one of the tied lexemes. There is actually a clever way to deal with this:First assign three values to each candidate lexeme &lt;synset s, lemma w&gt;a) the overlap score for the s. b) the .count() (frequency) for &lt;s,t&gt; where t is the target lemma. c) the .count() (frequency) for &lt;s,w&gt; Then, compute an aggregate score like this 1000*a + 100*b + c Sort all candidates by this score and select the highest (excluding lemmas that are identical to the target). This will automatically break ties. 1. Is the target lemma t = context.lemma?2. Is lemma w in &lt;synset s, lemma w&gt; any of the possible lemmas in s?Thank you in advance!",
    "answers": [
        "Yes and yes.\u00a0"
    ],
    "comments": []
}
{
    "question": "When I run a Python interpreter and try to include the Wordnet package, I get the following SSL error: \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate.\"  Some StackOverflow posts said to disable SSL checks, but can I confirm what is the best way to do this without totally disabling this? ",
    "answers": [],
    "comments": [
        "This sounds like you might be running into certificate errors when downloading the Wordnet package using Python. I don't know if you've already resolved this, but you could try installing a number of default Root Certificates for Python (assuming that you're on a Mac here).Try running:/Path-to-Python-Installation/Python\\ 3.9/Install\\ Certificates.commandIf you have something other than 3.9 installed, swap that out. Usually the path is:/Applications/PythonHopefully this resolves it for you. Disabling SSL checks would be risky if you forget to turn them back on."
    ]
}
{
    "question": "Hi all,Has anyone had any issues deploying a VM instance on GCP?I get this resource error:\"ResourceErrorMessage\":\"The zone 'projects/nlp-hw-394518/zones/us-west1-b' does not have enough resources available to fulfill the request. Try a different zone, or try again later.\"\nI have tried a few different regions and also waited a day but still no luck.Any advice would be appreciated.Many Thanks!",
    "answers": [
        "Having the same problem...I did part of my homework over the weekend, trying to finish it, no resources available for the past 2 days, tried moving to different zone, change machine type etc none worked. My data is practically stuck with GCP with no ways to retrieve it.I am just going to use lambda labs now: https://cloud.lambdalabs.com/instances at least it's a guarantee that you can make an instance, downside is 1) no persistent disk most of time (even if file system is available do save your data locally too otherwise when you need it the instance can attach disk might not be available) 2) you are paying out of pocket :(",
        "FWIW, I had this problem in a different class and using us-central1-a worked for me.",
        "Same here, I have tried a few different zones but still getting the error. "
    ],
    "comments": []
}
{
    "question": "Hello,I know we are allowed to bring a double-sided reference sheet in for the final. Is there some restriction in terms of what can be on it? For example: only formulas, etc.Thanks",
    "answers": [
        "There are no content restrictions for the cheat sheets. As long as you limit yours to one double-sided letter-sized sheet, you can add whatever you want to it."
    ],
    "comments": []
}
{
    "question": "Hi,Not sure if anyone else had this, but when I used the tokenize(s) function in part 3, I got an error as the compiler didn't recognize the \"string\" in \"string.punctuation\". When I added \"import string\" at the top of the file it seems to solve it.Hope a TA can confirm it's valid to add. Thanks!",
    "answers": [
        "Yes, please import string. "
    ],
    "comments": []
}
{
    "question": "Hi, for part 1 the description in Courseworks indicates we need to return a set of strings but the code indicates a list of strings; what is the expected return type?Thank you ",
    "answers": [
        "A set is the safer choice to make sure there are no duplicates.\u00a0"
    ],
    "comments": []
}
{
    "question": "Dear Prof. and TAs, For the part 6, if we want to try some ensemble learning methods or other improvement which would involve other packages or pre-trained models. Is this allowed? Thank you~",
    "answers": [
        "Yes, this is allowed. Just make sure to clearly comment on any required dependencies to run your code!"
    ],
    "comments": []
}
{
    "question": "Hi,I was a little confused about the difference between semantic and lexical ambiguity.I understand from the lectures that ambiguity can be broadly classified into structural and lexical ambiguity. Is semantic ambiguity a part of lexical ambiguity (and not structural), since there is confusion about the meaning interpretation?Thank you!",
    "answers": [
        "I don't believe the lecture notes explicitly describe the relationship between lexical ambiguity and semantic ambiguity. I looked on the internet and it states that lexical ambiguity is a subtype of semantic ambiguity, which I think makes sense since the lecture defines lexical ambiguity as a single word (e.g., \"mouse\") that has two or more possible meanings and the latter as a group of words (e.g., \"Stolen painting found by tree\") that have two or more possible meanings. Hope this helps!"
    ],
    "comments": []
}
{
    "question": "Dear Prof. and TAs,Here is my screenshot of prediction for part 2However, when I try to get the scores, it turns out the same as what for smuf. Would you mind helping me to check whether my prediction is problematic, or the command to call for the scoring is wrong?Thank you!",
    "answers": [
        "This could be an issue with the file format, rather than your prediction. The perl script expects unix style file endings (LF only), while the file may have windows style line endings (CL-RF)."
    ],
    "comments": []
}
{
    "question": "Hi folks,In terms of multiple parallel corpora, would using something like a multilingual Reuters dataset be sufficiently rigorous for the purposes of creating a corpus? I recognize that creative license may mean that the translations aren't necessarily perfect across different language versions of the same article, but would the faithfulness and fluency criteria likely be met?Thank you!",
    "answers": [
        "Sure that sounds like it would be a proper dataset for training an MT model.\u00a0"
    ],
    "comments": []
}
{
    "question": "If my BERT model performs somewhere between the WN frequency model and W2V, is that a definitive sign that my model has an issue? I am using BERT with the [MASK] token in the input.",
    "answers": [
        "I would expect the BERT model to work at least as well as the word2vec approach.\u00a0"
    ],
    "comments": []
}
{
    "question": "Question regarding DistilBERT tokenizer implementation - \"The encode method tokenizes a string, then adds special symbols [CLS] and [SEP], and then encodes the input into a sequence of integers.\"Can we assume that the input string has only alphabets? If they already consist of numbers, how should that be handled?Thank you!",
    "answers": [
        "You can assume the tokenizer handles numeric tokens correctly. Specifically it uses a kind of subword tokenization \u2014 we will discuss in more detail on Tuesday.\u00a0"
    ],
    "comments": []
}
{
    "question": "If this is the case (or if there is a tie), you should select the most frequent synset (i.e. the Synset with which the target word forms the most frequent lexeme, according to WordNet).So if there is a tie, do we pick the higher frequency one between the tie, or it's still the highest frequency from the entire set?Also, it is possible for the most frequent synset or the synset with most overlap to contain only one lemma that is the target word itself. In this situation, what are we suppose to do? Find the next possible synset or just return nothing?",
    "answers": [
        "You would break the tie, so return one of the tied lexemes.\u00a0There is actually a clever way to deal with this:First assign three values to each candidate lexeme &lt;synset s, lemma w&gt;a) the overlap score for the s.\u00a0b) the .count() (frequency) for &lt;s,t&gt; where t is the target lemma.\u00a0c) the .count() (frequency) for &lt;s,w&gt;\u00a0Then, compute an aggregate score like this 1000*a + 100*b + c\u00a0Sort all candidates by this score and select the highest (excluding lemmas that are identical to the target). \u00a0This will automatically break ties.\u00a0"
    ],
    "comments": []
}
{
    "question": "I'm wondering if the expectation for Part 6 for Homework 4 is for us to create a new function in the existing Predictor class or to create a new custom predictor class itself. And I am curious what type of innovative refinements are expected?Thanks in advance!",
    "answers": [
        "A new function is sufficient. The custom predictor does not have to perform significantly better than the other approaches in the assignment. Any interesting or creative solution will get full credit."
    ],
    "comments": []
}
{
    "question": "Hi, will submissions for HW 4 be opened soon? Thanks",
    "answers": [
        "It should be open now. Please try again.\u00a0"
    ],
    "comments": []
}
{
    "question": "My dev setup is ancient, so I ran into a number of issues when going through the installation steps for HW 4. Posting the solutions that worked for me here in case anyone else runs into the same issues.When trying to install gensim: error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\"Solution if you don't want to install all of VSCode: First answer in https://stackoverflow.com/questions/40018405/cannot-open-include-file-io-h-no-such-file-or-directory, though I chose the most recent compatible version of the packages instead.When trying to import gensim: ModuleNotFoundError: No module named 'dataclasses'Solution: pip install dataclassesWhen trying to install tokenizers: ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projectsSolution: Upgraded to Python 3.11. Maybe this would have solved some of the earlier problems too.The scoring script is written in Perl. You can install Perl at https://strawberryperl.com/ and restart your terminal for it take effect.",
    "answers": [
        "Adding on to this for anyone with M1 macs... I found these instructions helpful for resolving python &amp; tensorflow dependencies:  https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jan-2023.ipynb  "
    ],
    "comments": []
}
