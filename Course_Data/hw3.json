[
  {
    "context": "Homework 3 question 1: Obtaining the Vocabulary. In this assignment you will train a feed-forward neural network to predict the transitions of an arc-standard dependency parser. The input to this network will be a representation of the current state (including words on the stack and buffer). The output will be a transition (shift, left_arc, right_arc), together with a dependency relation label.\nMuch of the parser code  is provided, but you will need to implement the input representation for the neural net, decode the output of the network, and also specify the network architecture and train the model. The first 5 entries are special symbols. <CD> stands for any number (anything tagged with the POS tag CD), <NNP> stands for any proper name (anything tagged with the POS tag NNP). <UNK> stands for unknown words (in the training data, any word that appears only once). <ROOT> is a special root symbol (the word associated with the word 0, which is initially placed on the stack of the dependency parser). <NULL> is used to pad context windows",
    "statements": [
      {
        "source": "Run the following to generate an index of words and POS indices: $python get_vocab.py data/train.conll data/words.vocab data/pos.vocab\n This contains all words that appear more than once in the training data. What will the words look like?",
        "target": "<CD> 0\n<NNP> 1\n<UNK> 2\n<ROOT> 3\n<NULL> 4\nblocking 5\nhurricane 6\nships 7 "
      }
    ]
  },
  {
    "context": "Homework 3 question 2: Extracting Input/Output matrices for training. To train the neural network we first need to obtain a set of input/output training pairs. More specifically, each training example should be a pair (x,y), where x is a parser state and y is the transition the parser should make in that state.\n\nTake a look at the file extract_training_data.py \nStates: The input will be an instance of the class State, which represents a parser state. The attributes of this class consist of a stack, buffer, and partially built dependency structure deps. stack and buffer are lists of word ids (integers).\nThe top of the stack is the last word in the list stack[-1]. The next word on the buffer is also the last word in the list, buffer[-1].\nDeps is a list of (parent, child, relation) triples, where parent and child are integer ids and relation is a string (the dependency label). \n\nTransitions: The output is a pair (transition, label), where the transition can be one of \"shift\", \"left_arc\", or \"right_arc\" and the label is a dependency label. If the transition is \"shift\", the dependency label is None. Since there are 45 dependency relations (see list deps_relations), there are 45*2+1 possible outputs. \n\nObtaining oracle transitions and a sequence of input/output examples. \nAs discussed in class, we cannot observe the transitions directly from the treebank. We only see the resulting dependency structures. We therefore need to convert the trees into a sequence of (state, transition) pairs that we use for training. That part has already been implemented in the function get_training_instances(dep_structure). Given a DependencyStructure instance, this method returns a list of (State, Transition) pairs in the format described above. Your task will be to convert the input/output pairs into a representation suitable for the neural network. You will complete the method get_input_representation(self, words, pos, state) in the class FeatureExtractor. The constructor of the class FeatureExtractor takes the two vocabulary files as inputs (file objects). It then stores a word-to-index dictionary in the attribute word_vocab and POS-to-index dictionary in the attribute pos_vocab.",
    "statements": [
      {
        "source": "Implement get_input_representation(self, words, pos, state), tt takes as parameters a list of words in the input sentence, a list of POS tags in the input sentence and an instance of class State. It should return an encoding of the input to the neural network, i.e. a single vector. Write also get_output_representation(self, output_pair), which takes a (transition, label) pair as parameter and return a one-hot representation of these actions",
        "target": "    def get_input_representation(self, words, pos, state):\n        # TODO: Write this method for Part 2\n\n        input = np.array([-1, -1, -1, -1, -1, -1]) # default input array of length 6 filled with values of -1, which correspond to <NULL>\n\n        if len(state.stack) > 0:\n            input[0] = state.stack[-1] # first index filled with the top stack value\n            if len(state.stack) > 1:\n                input[1] = state.stack[-2] # second index filled with the second stack value\n                if len(state.stack) > 2:\n                    input[2] = state.stack[-3] # third index filled with the third stack value\n\n        if len(state.buffer) > 0:\n            input[3] = state.buffer[-1] # fourth index filled with the top buffer value\n            if len(state.buffer) > 1:\n                input[4] = state.buffer[-2] # fifth index filled with the second buffer value\n                if len(state.buffer) > 2:\n                    input[5] = state.buffer[-3] # last index filled with third buffer value\n\n        i = 0 # counter to keep track of indices in input array\n        for index in input: # iterating through each value in the input array (indices which correspond to words)\n            if index == -1: # if the value is still its default -1, then nothing was in the stack\n                input[i] = self.word_vocab['<NULL>'] # thus, that corresponding index is replaced with the dictionary value for <NULL>\n            else: # if the value is no longer its default -1, then it was replaced\n                word = str(words[index]) # getting the word according to the index given in the input array\n                if word == 'None': # if the word is None, then it is the root\n                    input[i] = self.word_vocab['<ROOT>'] # replace the index in the input array with the dictionary value for <ROOT>\n                elif str(pos[index]) == 'CD': # if the POS tag for the word is CD\n                    input[i] = self.word_vocab['<CD>'] # then replace the index in the input array with the dictionary value for <CD>\n                elif str(pos[index]) == 'NNP': # if the POS tag for the word is NNP\n                    input[i] = self.word_vocab['<NNP>'] # then replace the index in the input array with the dictionary value for <NNP>\n                elif word.lower() in self.word_vocab: # if the word is in the dictionary\n                    input[i] = self.word_vocab[word.lower()] # then replace the index in the input array with the dictionary value for that word\n                else: # if the word is not in the dictionary\n                    input[i] = self.word_vocab['<UNK>'] # replace that index in the input array with the dictionary value for <UNK>\n            i = i + 1 # iterating the counter so we can move to the next index in the input array\n\n        return input # returning the input array / representation\n \n     def get_output_representation(self, output_pair):\n        # TODO: Write this method for Part 2\n        output = np.zeros(91) # creating a 91-length array full of 0s\n\n        index = 0 # counter for which value in the output should be set to 1\n        if output_pair[0] == 'shift': # if the pair is (shift, None)\n            output[index] = 1 # the first index of the output array is set to 1\n        for relation in dep_relations: # iterating through each relation in the list of possible relations\n            if output_pair[0] == 'left_arc': # if it is a left arc transition\n                if output_pair[1] == relation: # and if the pair's relation is the same as the current relation\n                    output[index+1] = 1 # then the current odd index is set to 1\n            if output_pair[0] == 'right_arc': # if it is a right arc transition\n                if output_pair[1] == relation: # and if the pair's relation is the same as the current relation\n                    output[index+2] = 1 # then the current even index is set to 1\n            index = index + 2 # index is iterated by 2, because all odd indices are for left arc relations and all even indices are for right arc relations\n\n        return output # returning the output array / representation"
      }
    ]
  },
  {
    "context": "Homework 3 question 3: Designing and Training the network. Network topology Now that we have training data, we can build the actual neural net. In the file train_model.py, write the function build_model(word_types, pos_types, outputs). word_types is the number of possible words, pos_types is the number of possible POS, and outputs is the size of the output vector. Start by building a network as follows:\n\nOne Embedding layer, the input_dimension should be the number possible words, the input_length is the number of words using this same embedding layer. This should be 6, because we use the 3 top-word on the stack and the 3 next words on the buffer. \nThe output_dim of the embedding layer should be 32.\nA Dense hidden layer of 100 units using relu activation. (note that you want to Flatten the output of the embedding layer first).  \nA Dense hidden layer of 10 units using relu activation. \nAn output layer using softmax activation.\nFinally, the method should prepare the model for training, in this case using categorical crossentropy  as the loss and the Adam optimizer with a learning rate of 0.01.",
    "statements": [
      {
        "source": "Complete the build_model function that takes in word_types, pos_types, outputs and returns the model",
        "target": "def build_model(word_types, pos_types, outputs):\n    # TODO: Write this function for part 3\n\n    model = Sequential()\n    model.add(Embedding(word_types, 32, input_length=6)) # embedding layer\n    model.add(Flatten()) # flattening layer\n    model.add(Dense(100, activation='relu')) # dense layer of 100 units\n    model.add(Dense(10, activation='relu')) # dense layer of 10 units\n    model.add(Dense(91, activation='softmax')) # output layer with 91 units because there are 91 possible outputs and we need a dimension for each one\n    model.compile(keras.optimizers.Adam(lr=0.01), loss=\"categorical_crossentropy\")\n\n    return model"
      }
    ]
  },
  {
    "context": "Homework 3 question 4: Greedy Parsing Algorithm - Building and Evaluating the Parser. We will now use the trained model to construct a parser. In the file decoder.py, take a look at the class Parser. The class constructor takes the name of a keras model file, loads the model and stores it in the attribute model. It also uses the feature extractor from question 2. The algorithm is the standard transition-based algorithm. As long as the buffer is not empty, we use the feature extractor to obtain a representation of the current state. We then call model.predict(features) and retrieve a softmax actived vector of possible actions.",
    "statements": [
      {
        "source": "Write the method parse_sentence(self, words, pos), which takes as parameters a list of words and POS tags in the input sentence. The method will return an instance of DependencyStructure.",
        "target": "    def parse_sentence(self, words, pos):\n\n        state = State(range(1,len(words)))\n        state.stack.append(0)\n\n        # TODO: Write the body of this loop for part 4\n        while state.buffer:\n            arr = self.extractor.get_input_representation(words,pos,state) # getting the input representation\n            input = np.reshape(arr, (-1,6)) # reshaping the input to the appropriate size\n            prediction = (-self.model.predict(input)).argsort() # getting the prediction from the model, sorting the indices according to their corresponding values, and reversing that order so it's from max to min (most likely to least likely)\n            for index in prediction[0]: # iterating through the highest scoring predictions\n                transition = self.output_labels[index] # looking at the current best transition\n                # the following checks determine if the above transition is legal\n                if transition[0] == 'shift' and len(state.buffer) > 1 or (len(state.buffer) == 1 and len(state.stack) == 0):\n                # if the model predicts a shift, we have to check if the buffer has more than one element OR, if the stack is empty, then the buffer has at least one element\n                    state.shift() # if the conditions are met, then we can shift\n                    break # once the transition has been made, we break, because only one transition can be made at a time\n                elif transition[0] == 'left_arc' and len(state.stack) > 0 and state.stack[-1] != 0:\n                # if we can't shift, then we see if we can do a left arc, which can only be done if the stack isn't empty and if the top of the stack isn't the root\n                    state.left_arc(transition[1]) # if the conditions are met, then we can left arc transition\n                    break # once the transition has been made, we break, because only one transition can be made at a time\n                elif transition[0] == 'right_arc' and len(state.stack) > 0:\n                # if we can't shift or left_arc, then we see if we can do a right arc, which can only be done if the stack isn't empty\n                    state.right_arc(transition[1]) # if the conditions ar emet, then we can right arc transition\n                    break # once the transition has been made, we break, because only one transition can be made at a time\n\n        result = DependencyStructure()\n        for p,c,r in state.deps:\n            result.add_deprel(DependencyEdge(c,words[c],pos[c],p, r))\n\n        return result"
      }
    ]
  }
]